<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Abhishek Gupta | AI Ethics Researcher | Machine Learning Engineer</title>
    <link>https://atg-abhishek.github.io/categories/</link>
    <description>Recent content on Abhishek Gupta | AI Ethics Researcher | Machine Learning Engineer</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 31 Oct 2017 23:12:09 -0500</lastBuildDate>
    
	<atom:link href="https://atg-abhishek.github.io/categories/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Overview of my work</title>
      <link>https://atg-abhishek.github.io/about/workdetails/</link>
      <pubDate>Tue, 31 Oct 2017 23:12:09 -0500</pubDate>
      
      <guid>https://atg-abhishek.github.io/about/workdetails/</guid>
      <description>Current affiliations  Founder, Montreal AI Ethics Institute and a principal investigator for several projects happening at the Montreal AI Ethics Institute.
 Machine Learning Engineer, Microsoft on the Commercial Software Engineering (CSE) team at Microsoft where I work on machine learning projects involving both Azure ML services and open-source implementations. The hallmarks of the CSE team are that we operate in a “code-with” model with our customers. The team is deeply technical and highly specialized in solving the toughest technical challenges faced by Microsoft’s customers and the team follows an open-sourcing model to contribute the code and insights to the community from our engagements.</description>
    </item>
    
    <item>
      <title>Overview of my work</title>
      <link>https://atg-abhishek.github.io/about/workdetails/</link>
      <pubDate>Tue, 31 Oct 2017 23:12:09 -0500</pubDate>
      
      <guid>https://atg-abhishek.github.io/about/workdetails/</guid>
      <description>Current affiliations  Founder, Montreal AI Ethics Institute and a principal investigator for several projects happening at the Montreal AI Ethics Institute.
 Machine Learning Engineer, Microsoft on the Commercial Software Engineering (CSE) team at Microsoft where I work on machine learning projects involving both Azure ML services and open-source implementations. The hallmarks of the CSE team are that we operate in a “code-with” model with our customers. The team is deeply technical and highly specialized in solving the toughest technical challenges faced by Microsoft’s customers and the team follows an open-sourcing model to contribute the code and insights to the community from our engagements.</description>
    </item>
    
    <item>
      <title>Current Work</title>
      <link>https://atg-abhishek.github.io/about/currentwork/</link>
      <pubDate>Tue, 31 Oct 2017 22:26:09 -0500</pubDate>
      
      <guid>https://atg-abhishek.github.io/about/currentwork/</guid>
      <description>Featured picture courtesy of the McGill Physics Hackathon
Primary areas of research focus:  ML Retrospectives - a novel approach to making machine learning research transparent and accessible to colleagues in the scientific community. An emphasis on being retrospective about prior work and being comfortable with mistakes, transforming them into stepping stones for further scientific endeavours. For more information, please take a look here. This idea has been hosted as workshops at NeurIPS 2019, ICML 2020, and will be hosted at NeurIPS 2020.</description>
    </item>
    
    <item>
      <title>Current Work</title>
      <link>https://atg-abhishek.github.io/about/currentwork/</link>
      <pubDate>Tue, 31 Oct 2017 22:26:09 -0500</pubDate>
      
      <guid>https://atg-abhishek.github.io/about/currentwork/</guid>
      <description>Featured picture courtesy of the McGill Physics Hackathon
Primary areas of research focus:  ML Retrospectives - a novel approach to making machine learning research transparent and accessible to colleagues in the scientific community. An emphasis on being retrospective about prior work and being comfortable with mistakes, transforming them into stepping stones for further scientific endeavours. For more information, please take a look here. This idea has been hosted as workshops at NeurIPS 2019, ICML 2020, and will be hosted at NeurIPS 2020.</description>
    </item>
    
    <item>
      <title>Publications</title>
      <link>https://atg-abhishek.github.io/about/publications/</link>
      <pubDate>Tue, 31 Oct 2017 22:25:09 -0500</pubDate>
      
      <guid>https://atg-abhishek.github.io/about/publications/</guid>
      <description>Featured image courtesy of the Brookfield IIE
As seen in All copyrights and trademarks belong to the owners of the images
The importance of systems adaptability for meaningful Responsible AI deployment Towards Data Science Given that the sociotechnical environment within which AI systems are deployed are inherently dynamic and complex, we need the systems to be adaptable to mitigate negative consequences that arise from the deployment of these systems.</description>
    </item>
    
    <item>
      <title>Publications</title>
      <link>https://atg-abhishek.github.io/about/publications/</link>
      <pubDate>Tue, 31 Oct 2017 22:25:09 -0500</pubDate>
      
      <guid>https://atg-abhishek.github.io/about/publications/</guid>
      <description>Featured image courtesy of the Brookfield IIE
As seen in All copyrights and trademarks belong to the owners of the images
The importance of systems adaptability for meaningful Responsible AI deployment Towards Data Science Given that the sociotechnical environment within which AI systems are deployed are inherently dynamic and complex, we need the systems to be adaptable to mitigate negative consequences that arise from the deployment of these systems.</description>
    </item>
    
    <item>
      <title>Talks</title>
      <link>https://atg-abhishek.github.io/about/conferences/</link>
      <pubDate>Tue, 31 Oct 2017 22:24:09 -0500</pubDate>
      
      <guid>https://atg-abhishek.github.io/about/conferences/</guid>
      <description>Featured image courtesy of REWORK
SPEAKER csv,conf,v6 Talk on The Lab Notebook: Bringing Science Back to Data Science Conference Link
GUEST LECTURER KELLOGG SCHOOL OF MANAGEMENT - NORTHWESTERN UNIVERSITY - AI AND THE FUTURE OF WORK Guest lecture for MBA students on key lessons for organizations in responsible AI.
Invite-only session
TECHNICAL EXPERT UNITED NATIONS INSTITUTE FOR DISARMAMENT RESEARCH - MEANINGFUL HUMAN CONTROL FOR AUTONOMOUS WEAPONS SYSTEMS Table-top exercises in partnership with military, legal, and technical experts to assess meaningful human control in the context of autonomous weapons systems.</description>
    </item>
    
    <item>
      <title>Talks</title>
      <link>https://atg-abhishek.github.io/about/conferences/</link>
      <pubDate>Tue, 31 Oct 2017 22:24:09 -0500</pubDate>
      
      <guid>https://atg-abhishek.github.io/about/conferences/</guid>
      <description>Featured image courtesy of REWORK
SPEAKER csv,conf,v6 Talk on The Lab Notebook: Bringing Science Back to Data Science Conference Link
GUEST LECTURER KELLOGG SCHOOL OF MANAGEMENT - NORTHWESTERN UNIVERSITY - AI AND THE FUTURE OF WORK Guest lecture for MBA students on key lessons for organizations in responsible AI.
Invite-only session
TECHNICAL EXPERT UNITED NATIONS INSTITUTE FOR DISARMAMENT RESEARCH - MEANINGFUL HUMAN CONTROL FOR AUTONOMOUS WEAPONS SYSTEMS Table-top exercises in partnership with military, legal, and technical experts to assess meaningful human control in the context of autonomous weapons systems.</description>
    </item>
    
    <item>
      <title>Media Coverage</title>
      <link>https://atg-abhishek.github.io/about/mediacoverage/</link>
      <pubDate>Tue, 31 Oct 2017 22:22:09 -0500</pubDate>
      
      <guid>https://atg-abhishek.github.io/about/mediacoverage/</guid>
      <description>Featured image courtesy of AI for Good Global Summit
As seen in                                                        All copyrights and trademarks belong to the owners of the images</description>
    </item>
    
    <item>
      <title>Media Coverage</title>
      <link>https://atg-abhishek.github.io/about/mediacoverage/</link>
      <pubDate>Tue, 31 Oct 2017 22:22:09 -0500</pubDate>
      
      <guid>https://atg-abhishek.github.io/about/mediacoverage/</guid>
      <description>Featured image courtesy of AI for Good Global Summit
As seen in                                                        All copyrights and trademarks belong to the owners of the images</description>
    </item>
    
    <item>
      <title>Videos</title>
      <link>https://atg-abhishek.github.io/about/videos/</link>
      <pubDate>Tue, 31 Oct 2017 22:21:09 -0500</pubDate>
      
      <guid>https://atg-abhishek.github.io/about/videos/</guid>
      <description>Screenshot from the BorealisAI Northern Frontier Series featured interview on AI ethics
The Lab Notebook: Bringing Science back to Data Science TEPS March 2021 Seminar - York University All of us deal with data. A lot of us do data science. And yet only some of us get a chance to really infuse science into that data science work. Ever visit one of your old experiments and find that you want to pull out your hair because you are not sure how you arrived at some of the models that you ended up selecting, why you transformed your data the way you did, and other choices that now seem arbitrary but were perhaps perfectly reasonable then?</description>
    </item>
    
    <item>
      <title>Videos</title>
      <link>https://atg-abhishek.github.io/about/videos/</link>
      <pubDate>Tue, 31 Oct 2017 22:21:09 -0500</pubDate>
      
      <guid>https://atg-abhishek.github.io/about/videos/</guid>
      <description>Screenshot from the BorealisAI Northern Frontier Series featured interview on AI ethics
The Lab Notebook: Bringing Science back to Data Science TEPS March 2021 Seminar - York University All of us deal with data. A lot of us do data science. And yet only some of us get a chance to really infuse science into that data science work. Ever visit one of your old experiments and find that you want to pull out your hair because you are not sure how you arrived at some of the models that you ended up selecting, why you transformed your data the way you did, and other choices that now seem arbitrary but were perhaps perfectly reasonable then?</description>
    </item>
    
  </channel>
</rss>